{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "110d24bc-961f-4fc3-bd5a-693bfa67af99",
   "metadata": {},
   "source": [
    "# Cloud Types Segmentation Notebook\n",
    "\n",
    "This notebook allows the user to perform training on a custom UNet with skip connections using SatVision-TOA as the feature extractor.\n",
    "\n",
    "Data for this example is naively created for tutorial purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89237955-6d75-42f1-9b6d-e5bcd1c49272",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Installs/imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97db5d23-3a38-413e-9b67-7ab1fbc427d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import subprocess\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lightning as pl\n",
    "from huggingface_hub import snapshot_download\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e00463-e23c-4de3-a3ec-d0d583731a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"satvision-toa\"\n",
    "\n",
    "if not os.path.exists(repo_dir):\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/nasa-nccs-hpda/satvision-toa\"])\n",
    "else:\n",
    "    subprocess.run([\"git\", \"-C\", repo_dir, \"pull\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a4448-7cea-40b9-800b-9c411c691956",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('satvision-toa')\n",
    "from satvision_toa.utils import load_config\n",
    "from satvision_toa.models.mim import build_mim_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5ef0f8-4f7b-43aa-bbe4-7645998692ef",
   "metadata": {},
   "source": [
    "## Define Example Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f255c7c-ab93-41e6-a33e-3d6a7f89dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # logits: (B, C, H, W), targets: (B, H, W)\n",
    "        num_classes = logits.shape[1]\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        targets_one_hot = F.one_hot(targets, num_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "        dims = (0, 2, 3)\n",
    "        intersection = torch.sum(probs * targets_one_hot, dims)\n",
    "        cardinality = torch.sum(probs + targets_one_hot, dims)\n",
    "        dice_score = (2. * intersection + self.smooth) / (cardinality + self.smooth)\n",
    "        return 1. - dice_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62905232-30a7-402a-add1-d1dc04a4ab31",
   "metadata": {},
   "source": [
    "## Define Dummy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd485e8-4d23-4c85-88a9-9bb9c2f01d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyCloudDataset(Dataset):\n",
    "    def __init__(\n",
    "                self,\n",
    "                num_samples=100,\n",
    "                input_dims=(14, 128, 128),\n",
    "                mask_dims=(96, 40),\n",
    "                num_classes=9\n",
    "            ):\n",
    "        self.num_samples = num_samples\n",
    "        self.input_dims = input_dims\n",
    "        self.mask_dims = mask_dims\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chip = torch.rand(self.input_dims, dtype=torch.float32)\n",
    "        # multi-class mask (0â€“8)\n",
    "        mask = torch.randint(0, self.num_classes, self.mask_dims, dtype=torch.long)\n",
    "        return {\"chip\": chip, \"mask\": mask}\n",
    "\n",
    "\n",
    "def get_dummy_dataloader(batch_size=8, num_workers=0):\n",
    "    dataset = DummyCloudDataset()\n",
    "    return DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3af4d6-e0ee-4a57-82c9-4868df212a27",
   "metadata": {},
   "source": [
    "## Define SatVision-TOA UNet with Skip Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f771093d-b1b5-4992-bfa2-dffd609d75e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatVisionUNet(nn.Module):\n",
    "    def __init__(self, out_channels=9, freeze_encoder=True, input_channels=14, final_size=(96, 40)):\n",
    "        super().__init__()\n",
    "        self.final_size = final_size\n",
    "\n",
    "        # Load Swin encoder\n",
    "        config = load_config()\n",
    "        backbone = build_mim_model(config)\n",
    "        self.encoder = backbone.encoder\n",
    "\n",
    "        # Adjust input channels if needed\n",
    "        if input_channels != 14:\n",
    "            self.encoder.patch_embed.proj = nn.Conv2d(\n",
    "                input_channels,\n",
    "                self.encoder.patch_embed.proj.out_channels,\n",
    "                kernel_size=self.encoder.patch_embed.proj.kernel_size,\n",
    "                stride=self.encoder.patch_embed.proj.stride,\n",
    "                padding=self.encoder.patch_embed.proj.padding,\n",
    "                bias=False\n",
    "            )\n",
    "\n",
    "        # Load pretrained weights\n",
    "        checkpoint = torch.load(config.MODEL.RESUME, weights_only=False)\n",
    "        checkpoint = checkpoint['module']\n",
    "        checkpoint = {k.replace('model.encoder.', ''): v for k, v in checkpoint.items() if k.startswith('model.encoder')}\n",
    "        self.encoder.load_state_dict(checkpoint, strict=False)\n",
    "\n",
    "        # Freeze encoder\n",
    "        if freeze_encoder:\n",
    "            for p in self.encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        # Decoder\n",
    "        self.fusion_conv3 = nn.Conv2d(4096, 1024, 1)\n",
    "        self.fusion_conv2 = nn.Conv2d(2048, 512, 1)\n",
    "        self.fusion_conv1 = nn.Conv2d(1024, 256, 1)\n",
    "\n",
    "        self.upconv4 = nn.Sequential(nn.Conv2d(4096, 2048, 3, padding=1), nn.ReLU(), nn.Conv2d(2048, 1024, 3, padding=1))\n",
    "        self.upconv3 = nn.Sequential(nn.Conv2d(1024 + 1024, 1024, 3, padding=1), nn.ReLU(), nn.Conv2d(1024, 512, 3, padding=1))\n",
    "        self.upconv2 = nn.Sequential(nn.Conv2d(512 + 512, 512, 3, padding=1), nn.ReLU(), nn.Conv2d(512, 256, 3, padding=1))\n",
    "        self.upconv1 = nn.Sequential(nn.Conv2d(256 + 256, 256, 3, padding=1), nn.ReLU(), nn.Conv2d(256, 128, 3, padding=1))\n",
    "        self.upconv0 = nn.Sequential(nn.Conv2d(128, 128, 3, padding=1), nn.ReLU(), nn.Conv2d(128, 64, 3, padding=1))\n",
    "\n",
    "        # Final prediction layer (multi-class)\n",
    "        self.final = nn.Conv2d(64, out_channels, 1)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # Multi-scale encoder features\n",
    "        enc_features = self.encoder.extra_features(x)  # returns [stage1, stage2, stage3, stage4]\n",
    "        x = enc_features[-1]  # [B, 4096, 4, 4]\n",
    "\n",
    "        # Upconv4: 4x4 -> 8x8\n",
    "        x = F.interpolate(x, scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        x = self.upconv4(x)\n",
    "\n",
    "        # Upconv3: 8x8 -> 16x16 with fusion\n",
    "        x = F.interpolate(x, scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        enc_feat = F.interpolate(enc_features[2], size=x.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "        enc_feat = self.fusion_conv3(enc_feat)\n",
    "        x = torch.cat([x, enc_feat], dim=1)\n",
    "        x = self.upconv3(x)\n",
    "\n",
    "        # Upconv2: 16x16 -> 32x32 with fusion\n",
    "        x = F.interpolate(x, scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        enc_feat = F.interpolate(enc_features[1], size=x.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "        enc_feat = self.fusion_conv2(enc_feat)\n",
    "        x = torch.cat([x, enc_feat], dim=1)\n",
    "        x = self.upconv2(x)\n",
    "\n",
    "        # Upconv1: 32x32 -> 64x64 with fusion\n",
    "        x = F.interpolate(x, scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        enc_feat = F.interpolate(enc_features[0], size=x.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "        enc_feat = self.fusion_conv1(enc_feat)\n",
    "        x = torch.cat([x, enc_feat], dim=1)\n",
    "        x = self.upconv1(x)\n",
    "\n",
    "        # Final upconv: 64x64 -> 128x128\n",
    "        x = F.interpolate(x, scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        x = self.upconv0(x)\n",
    "        x = self.final(x)  # [B, 9, 128, 128]\n",
    "\n",
    "        # Resize to target (96, 40)\n",
    "        x = F.interpolate(x, size=self.final_size, mode=\"bilinear\", align_corners=False)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fef3f0-03bc-4a79-8362-c04cce6688aa",
   "metadata": {},
   "source": [
    "## Define the UNet Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec6a188-0d3c-4316-b530-18ccb00f8e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatVisionUNetLightning(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-4, dice_weight=0.5, freeze_encoder=True, num_classes=9):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = SatVisionUNet(out_channels=num_classes, freeze_encoder=freeze_encoder, input_channels=14, final_size=(96, 40))\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.dice_loss = DiceLoss()\n",
    "        self.dice_weight = dice_weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _common_step(self, batch, stage):\n",
    "        chips, masks = batch[\"chip\"], batch[\"mask\"]\n",
    "        logits = self.forward(chips)  # (B, C, H, W)\n",
    "        ce = self.ce_loss(logits, masks)\n",
    "        dice = self.dice_loss(logits, masks)\n",
    "        loss = self.dice_weight * dice + (1 - self.dice_weight) * ce\n",
    "        self.log(f'{stage}_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, b, i): return self._common_step(b, 'train')\n",
    "    def validation_step(self, b, i): return self._common_step(b, 'val')\n",
    "    def test_step(self, b, i): return self._common_step(b, 'test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c0a0c7-fb87-405b-8dae-481f36302b6d",
   "metadata": {},
   "source": [
    "## Define the Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0931ee72-9d54-44dd-98e4-e624443be8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SatVisionUNetLightning(\n",
    "    lr=1e-4,\n",
    "    dice_weight=0.5,\n",
    "    freeze_encoder=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada095f-04fa-47e5-91b5-d28da0a271c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_dummy_dataloader()\n",
    "val_loader = get_dummy_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8c964b-a874-43d4-a960-aa05a9610e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1\n",
    ")\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ILAB Kernel (Pytorch)",
   "language": "python",
   "name": "pytorch-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
