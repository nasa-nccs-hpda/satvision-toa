{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db5dcacd-4bb6-4aa0-a3d4-e49d03ad9ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6bd5095-a6d4-479b-ba06-0ca445847979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/ajkerr1/.nccstmp/ipykernel_2361237/3901150241.py:3: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import pkg_resources\n",
    "from collections import defaultdict\n",
    "\n",
    "def analyze_packages():\n",
    "    print(\"=== COMPREHENSIVE PACKAGE ANALYSIS ===\\n\")\n",
    "    \n",
    "    # Get pip list\n",
    "    result = subprocess.run([sys.executable, '-m', 'pip', 'list', '--format=json'], \n",
    "                           capture_output=True, text=True)\n",
    "    \n",
    "    pip_packages = {}\n",
    "    if result.returncode == 0:\n",
    "        import json\n",
    "        pip_data = json.loads(result.stdout)\n",
    "        pip_packages = {pkg['name'].lower(): pkg['version'] for pkg in pip_data}\n",
    "    \n",
    "    # Get pkg_resources info\n",
    "    pkg_resources_packages = {}\n",
    "    location_map = defaultdict(list)\n",
    "    \n",
    "    for dist in pkg_resources.working_set:\n",
    "        pkg_name = dist.project_name.lower()\n",
    "        pkg_resources_packages[pkg_name] = {\n",
    "            'version': dist.version,\n",
    "            'location': dist.location\n",
    "        }\n",
    "        location_map[dist.location].append(f\"{dist.project_name} ({dist.version})\")\n",
    "    \n",
    "    # Show packages by location\n",
    "    print(\"PACKAGES BY LOCATION:\")\n",
    "    for location in sys.path:\n",
    "        if location in location_map:\n",
    "            print(f\"\\n{location}:\")\n",
    "            for pkg in sorted(location_map[location]):\n",
    "                print(f\"  {pkg}\")\n",
    "    \n",
    "    # Show discrepancies\n",
    "    print(\"\\n=== PACKAGE STATUS ===\")\n",
    "    all_packages = set(pip_packages.keys()) | set(pkg_resources_packages.keys())\n",
    "    \n",
    "    for pkg in sorted(all_packages):\n",
    "        pip_version = pip_packages.get(pkg, \"NOT FOUND\")\n",
    "        pkg_resources_info = pkg_resources_packages.get(pkg, {})\n",
    "        pkg_resources_version = pkg_resources_info.get('version', \"NOT FOUND\")\n",
    "        location = pkg_resources_info.get('location', \"UNKNOWN\")\n",
    "        \n",
    "        status = \"✓\" if pip_version != \"NOT FOUND\" and pkg_resources_version != \"NOT FOUND\" else \"✗\"\n",
    "        print(f\"{status} {pkg:25} pip:{pip_version:15} pkg_resources:{pkg_resources_version:15}\")\n",
    "        \n",
    "        if pkg_resources_version != \"NOT FOUND\":\n",
    "            print(f\"    Location: {location}\")\n",
    "\n",
    "# analyze_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a38e8b0b-da9d-477d-b0d3-34cf2b08dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "import io\n",
    "import torch\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from huggingface_hub import snapshot_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a52bba5-594f-4d9b-96de-9f43847301dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(f\"Python executable: {sys.executable}\")\n",
    "# print(f\"Python version: {sys.version}\")\n",
    "# print(f\"\\nPython path (sys.path):\")\n",
    "# for i, path in enumerate(sys.path):\n",
    "#     print(f\"{i:2d}: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "379c1289-7895-4ed7-bb10-dcea1b1ac1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repo_dir = \"satvision-toa\"\n",
    "\n",
    "# if not os.path.exists(repo_dir):\n",
    "#     subprocess.run([\"git\", \"clone\", \"https://github.com/nasa-nccs-hpda/satvision-toa\"])\n",
    "# else:\n",
    "#     subprocess.run([\"git\", \"-C\", repo_dir, \"pull\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed7eb36e-2a4a-4831-90f0-a9703b95ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../../satvision-toa/\")\n",
    "# sys.path.append(\"satvision-toa\")\n",
    "from satvision_toa.configs.config import _C, _update_config_from_file\n",
    "from satvision_toa.models.mim import build_mim_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7b28096-492f-4c51-963f-f81e3faed7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from satvision_toa.datasets.ocean_color_dataset import OceanColorDataset\n",
    "from satvision_toa.models.decoders.ocean_color_decoder import (\n",
    "    OceanColorUNETV2, OceanColorFCNV3,\n",
    "    OceanColorFCNV2, OceanColorFCNV2point5\n",
    ")\n",
    "from satvision_toa.models.decoders.ocean_color_e2e_decoder import (\n",
    "    OceanColorFCN, OceanColorUNET\n",
    ")\n",
    "\n",
    "from satvision_toa.transforms.ocean_color import (\n",
    "    GlobalMinMaxNorm, PBMinMaxNorm, ScaleAndOffset\n",
    ")\n",
    "\n",
    "from satvision_toa.data_utils.utils_ocean_color import (\n",
    "    load_config, get_dataloaders, train_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a797ebfd-9f59-4615-b699-e0b9ad0a3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dir = \"/panfs/ccds02/nobackup/people/ajkerr1/SatVision/OceanColor\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba94d830-f612-4ce9-8f5c-a6a00b5a7080",
   "metadata": {},
   "source": [
    "## SV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c97ff3f-a621-4338-beed-a3addfae3220",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(full_dir, \"chips/ft/chips_ft\")\n",
    "test_dir = os.path.join(full_dir, \"chips/ft/val_chips_ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10d3c092-33b0-4460-b682-98c902e121d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> merge config from /home/ajkerr1/.cache/huggingface/hub/models--nasa-cisto-data-science-group--downstream-satvision-toa-3dclouds/snapshots/1c6d3b4fba1a476956027e56d5dd9708bdfef0ba/mim_pretrain_swinv2_satvision_giant_128_window08_50ep.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/panfs/ccds02/app/modules/jupyter/ilab/dev/kernel/lib/python3.12/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1720538439675/work/aten/src/ATen/native/TensorShape.cpp:3609.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing encoder\n"
     ]
    }
   ],
   "source": [
    "config = load_config()\n",
    "model = build_mim_model(config)\n",
    "model = OceanColorFCNV2point5(\n",
    "    swin_encoder=model.encoder, freeze_encoder=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd8dc5da-c028-479e-b80e-e13baa0e8fa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train & val size: (144, 37)\n",
      "Decoder weights initialized with Kaiming/Xavier initialization\n",
      "Starting training for 100 epochs on cuda\n",
      "Model parameters: 640,583,393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Epoch 1/100 [Train]:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A/panfs/ccds02/app/modules/jupyter/ilab/dev/kernel/lib/python3.12/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "\n",
      "Epoch 1/100 [Train]:   0%|          | 0/6 [00:07<?, ?it/s, Loss=0.339812, Avg=0.339812, LR=1.00e-04]\u001b[A\n",
      "Epoch 1/100 [Train]:  17%|█▋        | 1/6 [00:07<00:38,  7.66s/it, Loss=0.339812, Avg=0.339812, LR=1.00e-04]\u001b[A\n",
      "Epoch 1/100 [Train]:  17%|█▋        | 1/6 [00:13<00:38,  7.66s/it, Loss=0.357237, Avg=0.348525, LR=1.00e-04]\u001b[A\n",
      "Epoch 1/100 [Train]:  33%|███▎      | 2/6 [00:13<00:27,  6.77s/it, Loss=0.357237, Avg=0.348525, LR=1.00e-04]\u001b[A\n",
      "Epoch 1/100 [Train]:  33%|███▎      | 2/6 [00:19<00:27,  6.77s/it, Loss=0.332436, Avg=0.343162, LR=1.00e-04]\u001b[A\n",
      "Epoch 1/100 [Train]:  50%|█████     | 3/6 [00:19<00:19,  6.50s/it, Loss=0.332436, Avg=0.343162, LR=1.00e-04]\u001b[A\n",
      "Epoch 1/100 [Train]:  50%|█████     | 3/6 [00:26<00:19,  6.50s/it, Loss=0.301666, Avg=0.332788, LR=1.00e-04]\u001b[A\n",
      "Epoch 1/100 [Train]:  67%|██████▋   | 4/6 [00:26<00:12,  6.37s/it, Loss=0.301666, Avg=0.332788, LR=1.00e-04]\u001b[A\n",
      "Epoch 1/100 [Train]:  67%|██████▋   | 4/6 [00:32<00:12,  6.37s/it, Loss=0.295985, Avg=0.325427, LR=1.00e-04]\u001b[A\n",
      "Epoch 1/100 [Train]:  83%|████████▎ | 5/6 [00:32<00:06,  6.30s/it, Loss=0.295985, Avg=0.325427, LR=1.00e-04]\u001b[A\n",
      "Epoch 1/100 [Train]:  83%|████████▎ | 5/6 [00:33<00:06,  6.30s/it, Loss=0.374337, Avg=0.333579, LR=1.00e-04]\u001b[A\n",
      "Epoch 1/100 [Train]: 100%|██████████| 6/6 [00:33<00:00,  4.52s/it, Loss=0.374337, Avg=0.333579, LR=1.00e-04]\u001b[A\n",
      "                                                                                                            \u001b[A\n",
      "Epoch 1/100 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1/100 [Val]:   0%|          | 0/1 [00:01<?, ?it/s, Loss=0.483784, MAE=0.471661]\u001b[A\n",
      "Epoch 1/100 [Val]: 100%|██████████| 1/1 [00:01<00:00,  1.49s/it, Loss=0.483784, MAE=0.471661]\u001b[A\n",
      "                                                                                             \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Testing: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\u001b[A\n",
      "Training Progress:   1%|          | 1/100 [00:38<1:03:55, 38.74s/it, Train_Loss=0.3336, Val_Loss=0.4838, Val_MAE=0.4717, Time=38.7s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots saved to pred_pdfs/svtoa/preds_day_2025_07_28_time_11_05_1ep.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/100 [Train]:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A/panfs/ccds02/app/modules/jupyter/ilab/dev/kernel/lib/python3.12/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "\n",
      "Training Progress:   1%|          | 1/100 [00:45<1:14:34, 45.20s/it, Train_Loss=0.3336, Val_Loss=0.4838, Val_MAE=0.4717, Time=38.7s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m pdf_path = \u001b[33m\"\u001b[39m\u001b[33mpred_pdfs/svtoa\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m metrics_filename = \u001b[33m\"\u001b[39m\u001b[33msv_metrics\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m train_losses, val_losses = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_every\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_every\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetrics_filename\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/panfs/ccds02/nobackup/people/ajkerr1/SatVision/OceanColor/satvision-toa/examples/downstream_ocean_colors/../../../satvision-toa/satvision_toa/data_utils/utils_ocean_color.py:238\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_dataloader, val_dataloader, test_dataloader, num_epochs, learning_rate, weight_decay, device, save_path, log_interval, save_every, test_every, pdf_path, metrics_filename)\u001b[39m\n\u001b[32m    235\u001b[39m loss = criterion(output, target)\n\u001b[32m    237\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[38;5;66;03m# Gradient clipping\u001b[39;00m\n\u001b[32m    241\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/panfs/ccds02/app/modules/jupyter/ilab/dev/kernel/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    512\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    513\u001b[39m         Tensor.backward,\n\u001b[32m    514\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    519\u001b[39m         inputs=inputs,\n\u001b[32m    520\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/panfs/ccds02/app/modules/jupyter/ilab/dev/kernel/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    284\u001b[39m     retain_graph = create_graph\n\u001b[32m    286\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/panfs/ccds02/app/modules/jupyter/ilab/dev/kernel/lib/python3.12/site-packages/torch/autograd/graph.py:768\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    766\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    769\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ADJUST FOR TRAINING UNET VS SATVISION\n",
    "train_dataloader, val_dataloader, test_dataloader = get_dataloaders(\n",
    "    train_dir, test_dir, num_inputs=14, batch_size=64\n",
    ")\n",
    "\n",
    "num_epochs = 100\n",
    "save_every = 20\n",
    "test_every = 10\n",
    "save_path = \"sv_unet\"\n",
    "pdf_path = \"pred_pdfs/svtoa\"\n",
    "metrics_filename = \"sv_metrics\"\n",
    "train_losses, val_losses = train_model(\n",
    "    model, train_dataloader, val_dataloader, test_dataloader, num_epochs=num_epochs, \n",
    "    save_path=save_path, save_every=save_every, test_every=test_every, pdf_path=pdf_path, \n",
    "    metrics_filename=metrics_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253b22cc-acb2-444e-8527-af982eb596ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(40, 25))\n",
    "ax1.plot(train_losses, label=\"Train Loss\")\n",
    "ax2.plot(val_losses, label=\"Val Loss\")\n",
    "ax1.set_xlabel(\"Epoch\", fontsize=25)\n",
    "ax2.set_xlabel(\"Epoch\", fontsize=25)\n",
    "ax1.set_ylabel(\"Loss\", fontsize=25)\n",
    "ax2.set_ylabel(\"Loss\", fontsize=25)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax1.set_title(\"Training Loss\", fontsize=30)\n",
    "ax2.set_title(\"Validation Loss\", fontsize=30)\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d1259-0ed9-4c75-b501-f8b545e67fb1",
   "metadata": {},
   "source": [
    "## Plain UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b80d6-861d-42f4-abb3-1152d2be315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(full_dir, \"chips/e2e/chips_6_27\")\n",
    "test_dir = os.path.join(full_dir, \"chips/e2e/val_chips_e2e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d823d-1ef9-4a0c-ac21-468e5a4b7afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OceanColorUNET(in_channels=12, out_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390dd67e-9092-4a88-b527-338a71996a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADJUST FOR TRAINING UNET VS SATVISION\n",
    "train_dataloader, val_dataloader, test_dataloader = get_dataloaders(\n",
    "    train_dir, test_dir, num_inputs=12, batch_size=64\n",
    ")\n",
    "\n",
    "num_epochs = 2\n",
    "save_every = 20\n",
    "test_every = 10\n",
    "save_path = \"e2e_unet\"\n",
    "pdf_path = \"pred_pdfs/e2e\"\n",
    "metrics_filename = \"e2e_metrics\"\n",
    "train_losses, val_losses = train_model(\n",
    "    model, train_dataloader, val_dataloader, test_dataloader, num_epochs=num_epochs, \n",
    "    save_path=save_path, save_every=save_every, test_every=test_every, pdf_path=pdf_path, \n",
    "    metrics_filename=metrics_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3f411-bf4f-42bc-a466-676f47751ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(40, 25))\n",
    "ax1.plot(train_losses, label=\"Train Loss\")\n",
    "ax2.plot(val_losses, label=\"Val Loss\")\n",
    "ax1.set_xlabel(\"Epoch\", fontsize=25)\n",
    "ax2.set_xlabel(\"Epoch\", fontsize=25)\n",
    "ax1.set_ylabel(\"Loss\", fontsize=25)\n",
    "ax2.set_ylabel(\"Loss\", fontsize=25)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax1.set_title(\"Training Loss\", fontsize=30)\n",
    "ax2.set_title(\"Validation Loss\", fontsize=30)\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14eb16b-74c9-4138-8b96-ecb05a1ebfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('e2e_metrics_epoch_metrics_average.csv')\n",
    "df = df[['epoch', 'r2', 'rmse', 'ssim', 'psnr']]\n",
    "df.plot(x='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7378aa01-a18c-4fc3-b88a-3d4b470fd564",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sv_metrics_epoch_metrics_average.csv')\n",
    "df = df[['epoch', 'r2', 'rmse', 'ssim', 'psnr']]\n",
    "df1 = df.iloc[0:21]\n",
    "df2 = df.iloc[21:]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "axes = np.array(axes).flatten()\n",
    "metric_columns = ['r2', 'rmse', 'ssim', 'psnr']\n",
    "for idx, metric in enumerate(metric_columns):\n",
    "    axes[idx].plot(df['epoch'], df[metric], label=metric)\n",
    "    axes[idx].set_title(f'{metric.upper()} vs Epoch')\n",
    "    axes[idx].set_xlabel('Epoch')\n",
    "    axes[idx].set_ylabel(metric.upper())\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    axes[idx].xaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b7394-36fa-4e0b-b203-9085403b114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('e2e_metrics_epoch_metrics_average.csv')\n",
    "df = df[['epoch', 'r2', 'rmse', 'ssim', 'psnr']]\n",
    "df1 = df.iloc[0:21]\n",
    "df2 = df.iloc[21:]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "axes = np.array(axes).flatten()\n",
    "metric_columns = ['r2', 'rmse', 'ssim', 'psnr']\n",
    "for idx, metric in enumerate(metric_columns):\n",
    "    axes[idx].plot(df['epoch'], df[metric], label=metric)\n",
    "    axes[idx].set_title(f'{metric.upper()} vs Epoch')\n",
    "    axes[idx].set_xlabel('Epoch')\n",
    "    axes[idx].set_ylabel(metric.upper())\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    axes[idx].xaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEV Kernel",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
