{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5facdc34-efbd-4082-91ef-e70a4f34c441",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SatVision-TOA Reconstruction Example Notebook\n",
    "\n",
    "This notebook demonstrates the reconstruction capabilities of the SatVision-TOA model, designed to process and reconstruct MODIS TOA (Top of Atmosphere) imagery using Masked Image Modeling (MIM) for Earth observation tasks.\n",
    "\n",
    "Follow this step-by-step guide to install necessary dependencies, load model weights, transform data, make predictions, and visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2578e3bb-506f-4e15-83bd-20b460ea08d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Setup and Install Dependencies\n",
    "\n",
    "The following packages are required to run the notebook:\n",
    "- `yacs` – for handling configuration\n",
    "- `timm` – for Transformer and Image Models in PyTorch\n",
    "- `segmentation-models-pytorch` – for segmentation utilities\n",
    "- `termcolor` – for colored terminal text\n",
    "- `webdataset==0.2.86` – for handling datasets from web sources\n",
    "- `huggingface-hub` - for downloading Hugging Face files\n",
    "- `datasets` - for running model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6781e1-d029-4d10-ad36-3f78c9be8de5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.1 Install necessary modules, clone github repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e08cd1-d8df-4dd8-b884-d452ef90943b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install yacs timm segmentation-models-pytorch termcolor webdataset==0.2.86 huggingface-hub datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b7257a-a6e2-4d16-ba87-ef19cf67108b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.2 Imports\n",
    "**Some modules may require some path configurations (often installed in .local or .cache directories)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4506576-5e30-417d-96de-8953d71c76c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "import datasets\n",
    "import datetime\n",
    "import warnings\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import hf_hub_download\n",
    "from huggingface_hub import snapshot_download\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1748b2-8de8-4dc9-a0b7-493f48341ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"satvision-toa\"\n",
    "\n",
    "if not os.path.exists(repo_dir):\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/nasa-nccs-hpda/satvision-toa\"])\n",
    "else:\n",
    "    subprocess.run([\"git\", \"-C\", repo_dir, \"pull\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775cb720-5151-49fa-a7d5-7291ef663d45",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.3 Repository-Specific Imports\n",
    "\n",
    "We load necessary modules from the pytorch-caney library, including the model, transformations, and plotting utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf47149-f489-497b-8601-89a7e8dbd9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append('../..')\n",
    "sys.path.append('satvision-toa')\n",
    "from satvision_toa.models.mim import build_mim_model\n",
    "from satvision_toa.transforms.mim_modis_toa import MimTransform\n",
    "from satvision_toa.configs.config import _C, _update_config_from_file\n",
    "from satvision_toa.plotting.modis_toa import plot_export_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd7bc9-9ad6-4cc7-b3a5-eb8db32b66d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. User-defined variables\n",
    "\n",
    "**save_to_pdf** and **pdf_path** dictate whether to save model inference images to PDF, and where to save them to.\n",
    "\n",
    "**rgb_index** is the indices of RGB bands in model input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619465b-6efc-4695-b31f-c0bf10185586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether to save files to a PDF, and where to save them \n",
    "save_to_pdf = False\n",
    "pdf_path = \"chip_plot.pdf\" # if not saving this can be None\n",
    "\n",
    "# Indices of RGB bands within 14-band data\n",
    "rgb_index = [0, 2, 1]\n",
    "\n",
    "# Model size to download\n",
    "model_size: str = 'giant'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e980f9-a89c-48f2-9e64-b731263341ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Downlad model, validation files from HF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d24dfed-b111-4a87-9a88-0c76e4f1655c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 Download model and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f011f-c584-4f26-9c12-5466206a03aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_options_metadata = {\n",
    "    'giant': {\n",
    "        'repo_id': 'nasa-cisto-data-science-group/satvision-toa-giant-patch8-window8-128',\n",
    "        'model_filename': 'mp_rank_00_model_states.pt',\n",
    "        'config_filename': 'mim_pretrain_swinv2_satvision_giant_128_window08_50ep.yaml'\n",
    "    },\n",
    "    'huge': {\n",
    "        'repo_id': 'nasa-cisto-data-science-group/satvision-toa-huge-patch8-window8-128',\n",
    "        'model_filename': 'mp_rank_00_model_states.pt',\n",
    "        'config_filename': 'mim_pretrain_swinv2_satvision_huge_128_window8_patch8_100ep.yaml'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43558242-3217-43d6-a2d4-1c7ef990937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model_repo_id: str = model_options_metadata[model_size]['repo_id']\n",
    "hf_model_filename: str = model_options_metadata[model_size]['model_filename']\n",
    "hf_config_filename: str = model_options_metadata[model_size]['config_filename']\n",
    "hf_dataset_repo_id: str = 'nasa-cisto-data-science-group/modis_toa_cloud_reconstruction_validation'\n",
    "\n",
    "model_filename = hf_hub_download(\n",
    "    repo_id=hf_model_repo_id,\n",
    "    filename=hf_model_filename)\n",
    "config_filename = hf_hub_download(\n",
    "    repo_id=hf_model_repo_id,\n",
    "    filename=hf_config_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1462b7-9680-4b55-8506-026852322c7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.2 Download and transform validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f41e006-d264-4beb-83ff-880a471c7735",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download the dataset\n",
    "validation_tiles_dir = snapshot_download(repo_id=hf_dataset_repo_id, allow_patterns=\"*.npy\", repo_type='dataset')\n",
    "validation_tiles_regex = os.path.join(validation_tiles_dir, '*.npy')\n",
    "validation_tiles_filename = next(iter(glob.glob(validation_tiles_regex)))\n",
    "validation_tiles = np.load(validation_tiles_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719974a6-b27f-419c-9964-e6e07b4d1362",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3 Load and edit model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaea45d-c875-4fa4-a91d-f48ca9c43b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = _C.clone()\n",
    "_update_config_from_file(config, config_filename)\n",
    "\n",
    "# Add checkpoint (MODEL.PRETRAINED), \n",
    "# validation tile dir (DATA.DATA_PATHS),\n",
    "# and output dir (OUTPUT) to config file\n",
    "config.defrost()\n",
    "config.MODEL.PRETRAINED = model_filename\n",
    "config.DATA.DATA_PATHS = validation_tiles_filename\n",
    "config.OUTPUT = '.'\n",
    "config.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3b47b1-0690-4ef9-bed6-ec243b5d42cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Masked-Image-Modeling transform specific to MODIS TOA data\n",
    "transform = MimTransform(config)\n",
    "\n",
    "# The reconstruction evaluation set is a single numpy file\n",
    "len_batch = range(validation_tiles.shape[0])\n",
    "\n",
    "# Apply transform to each image in the batch\n",
    "# A mask is auto-generated in the transform\n",
    "imgMasks = [transform(validation_tiles[idx]) for idx \\\n",
    "    in len_batch]\n",
    "\n",
    "# Seperate img and masks, cast masks to torch tensor\n",
    "img = torch.stack([imgMask[0] for imgMask in imgMasks])\n",
    "mask = torch.stack([torch.from_numpy(imgMask[1]) for \\\n",
    "    imgMask in imgMasks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae37562-7ae2-4598-9d5c-7f5c535823e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Build model\n",
    "\n",
    "Model checkpoint and weights are stored in config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d3ca8-5d61-4572-b6bc-4f229853efba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Building un-initialized model')\n",
    "model = build_mim_model(config)\n",
    "print('Successfully built uninitialized model')\n",
    "\n",
    "print(f'Attempting to load checkpoint from {config.MODEL.PRETRAINED}')\n",
    "checkpoint = torch.load(config.MODEL.PRETRAINED)\n",
    "model.load_state_dict(checkpoint['module'])\n",
    "print('Successfully applied checkpoint')\n",
    "model.cuda()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2148e4-da6d-4ae0-a194-c7adb62728a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Prediction\n",
    "\n",
    "Run predictions on each sample and calculate reconstruction losses. Each image is processed individually to track individual losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3814751-f352-456e-850c-fe1d289b1d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "masks = []\n",
    "losses = []\n",
    "\n",
    "# We could do this in a single batch however we\n",
    "# want to report the loss per-image, in place of\n",
    "# loss per-batch.\n",
    "for i in tqdm(range(img.shape[0])):\n",
    "    single_img = img[i].unsqueeze(0)\n",
    "    single_mask = mask[i].unsqueeze(0)\n",
    "    single_img = single_img.cuda(non_blocking=True)\n",
    "    single_mask = single_mask.cuda(non_blocking=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z = model.encoder(single_img, single_mask)\n",
    "        img_recon = model.decoder(z)\n",
    "        loss = model(single_img, single_mask)\n",
    "\n",
    "    inputs.extend(single_img.cpu())\n",
    "    masks.extend(single_mask.cpu())\n",
    "    outputs.extend(img_recon.cpu())\n",
    "    losses.append(loss.cpu()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edd6e5a-23cc-4523-a354-b6514296c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0].shape\n",
    "# inputs is a 128-length list of [14, 128, 128] shape chips\n",
    "# outputs is a 128-length list of [14, 128, 128] shape chips\n",
    "# masks is a 128-length list of [32, 32] masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22329bb4-5c6e-42dc-a492-8863fc2bf672",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Plot reconstruction\n",
    "\n",
    "*Using the plot_export_pdf found in satvision_toa/plotting/modis_toa.py*\n",
    "\n",
    "This will display model reconstruction and mask, compared with model input. It will save to a pdf file defined in pdf_path if save_to_pdf is True. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadaa172-65b3-42c3-bbb8-f521fa00e12c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_export_pdf(pdf_path, inputs, outputs, masks, rgb_index, save_to_pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEV Kernel",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
