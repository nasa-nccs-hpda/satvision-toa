{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edec4a2f-c71c-4779-bf8a-e718dc9cecb4",
   "metadata": {},
   "source": [
    "# SatVision Inference Using Triton Server Inside NASA GSFC\n",
    "\n",
    "This Jupyter Notebook demonstrates how to perform inference using the SatVision foundation model deployed on a Triton Inference Server inside NASA GSFC. It walks through the end-to-end process of formatting inputs, sending requests to the server, and retrieving model predictions. The notebook is designed to support high-throughput inference for multi-channel MODIS TOA data, leveraging GPU acceleration and Tritonâ€™s efficient serving capabilities for scalable downstream applications.\n",
    "\n",
    "The idea of this server is to deploy the model so users can extract the features needed for model training, and then be able to train their new models without the resources needed to run SatVision-TOA.\n",
    "\n",
    "## 1. Download Configuration Dependencies\n",
    "\n",
    "### 1.1. Download SatVision Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6561a393-defb-41f8-8aa0-66ea7226543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import urllib\n",
    "import subprocess\n",
    "import gevent.ssl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tritonclient.http as httpclient\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import hf_hub_download\n",
    "from huggingface_hub import snapshot_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996fac7b-ce6f-4b69-9c91-ffaa0d8857b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_url = \"https://github.com/nasa-nccs-hpda/satvision-toa\"\n",
    "if not os.path.exists('satvision-toa'):\n",
    "    subprocess.run([\"git\", \"clone\", repo_url, 'satvision-toa'], check=True)\n",
    "    print(f\"Cloned {repo_url} into satvision-toa\")\n",
    "else:\n",
    "    print(\"Repository already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea38d2c3-0b08-4b1e-93eb-b81b28e41f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_url = \"https://huggingface.co/nasa-cisto-data-science-group/\" + \\\n",
    "    \"satvision-toa-giant-patch8-window8-128/resolve/main/\" + \\\n",
    "    \"mim_pretrain_swinv2_satvision_giant_128_window08_50ep.yaml\"\n",
    "config_output_path = os.path.join(\"mim_pretrain_swinv2_satvision_giant_128_window08_50ep.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936947e-d6b5-43cb-8480-2274bccd26a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(config_output_path):\n",
    "    urllib.request.urlretrieve(config_url, config_output_path)\n",
    "    print(f\"Downloaded to {config_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e8152b-5907-445c-9f1a-932387d3fc3c",
   "metadata": {},
   "source": [
    "### 1.2. Setup SatVision Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469cd004-3c3c-4bb0-994d-f8f9b4c1c59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the path and dependencies\n",
    "sys.path.append('satvision-toa')\n",
    "from satvision_toa.models.mim import build_mim_model\n",
    "from satvision_toa.transforms.mim_modis_toa import MimTransform\n",
    "from satvision_toa.configs.config import _C, _update_config_from_file\n",
    "from satvision_toa.plotting.modis_toa import plot_export_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6145805e-4419-497b-bb19-8f6579c101d6",
   "metadata": {},
   "source": [
    "## 1.3 Load SatVision Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ecc67f-6af1-4197-9d33-89f8f6a89781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model config\n",
    "config = _C.clone()\n",
    "_update_config_from_file(config, config_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5785212d-c213-43da-8023-fef7642ec43a",
   "metadata": {},
   "source": [
    "# 2. Setup Triton Server Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e3eab-7a48-4167-8864-acc9395f411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "triton_server_url = \"gs6n-dgx02.sci.gsfc.nasa.gov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc7bb79-be20-4c4a-8a42-d70ac52f68ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Triton client\n",
    "ssl_context_factory = gevent.ssl._create_unverified_context\n",
    "client = httpclient.InferenceServerClient(\n",
    "    url=triton_server_url,\n",
    "    ssl=True,\n",
    "    insecure=True,\n",
    "    ssl_context_factory=ssl_context_factory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc5e8d8-f5ff-44ec-9471-bf555cbe14a6",
   "metadata": {},
   "source": [
    "# 3. Download Data from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5102e-b0ca-4baa-813a-cce95243240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset_repo_id: str = 'nasa-cisto-data-science-group/modis_toa_cloud_reconstruction_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00790eb4-ebfc-4671-b722-edf6000163c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_tiles_dir = snapshot_download(repo_id=hf_dataset_repo_id, allow_patterns=\"*.npy\", repo_type='dataset')\n",
    "validation_tiles_regex = os.path.join(validation_tiles_dir, '*.npy')\n",
    "validation_tiles_filename = next(iter(glob(validation_tiles_regex)))\n",
    "validation_tiles = np.load(validation_tiles_filename)\n",
    "validation_tiles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a01c8d-3ef8-4275-87cb-e5e7e974d2db",
   "metadata": {},
   "source": [
    "# 3. Perfom Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e6eaea-c754-4b6c-b272-d29298115d80",
   "metadata": {},
   "source": [
    "## 3.1 Apply Transform\n",
    "\n",
    "This section will be performed at the triton server at a later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b66a6-9504-4eef-aaab-2d4ec20fa84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Masked-Image-Modeling transform specific to MODIS TOA data\n",
    "transform = MimTransform(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f280d-180d-4013-a584-a1de394911a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transform to each image in the batch\n",
    "# A mask is auto-generated in the transform\n",
    "images_and_masks = [transform(validation_tiles[idx]) for idx \\\n",
    "    in range(validation_tiles.shape[0])]\n",
    "\n",
    "# Seperate img and masks, cast masks to torch tensor\n",
    "images = np.stack([image_mask_list[0] for image_mask_list in images_and_masks])\n",
    "masks = np.stack([image_mask_list[1] for image_mask_list in images_and_masks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20b5c31-a15d-46e5-b09d-71de2d319ac5",
   "metadata": {},
   "source": [
    "## 3.2 Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01de328-f40f-4860-b1fd-a24d64d57579",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = []\n",
    "input_masks = []\n",
    "output_images = []\n",
    "\n",
    "for i in tqdm(range(validation_tiles.shape[0])):\n",
    "\n",
    "    single_image, single_mask = np.expand_dims(images[i], 0), np.expand_dims(masks[i], 0).astype(bool)\n",
    "\n",
    "    # Prepare input tensors\n",
    "    image_tensor = httpclient.InferInput(\"image\", single_image.shape, \"FP32\")\n",
    "    image_tensor.set_data_from_numpy(single_image)\n",
    "\n",
    "    mask_tensor = httpclient.InferInput(\"mask\", single_mask.shape, \"BOOL\")\n",
    "    mask_tensor.set_data_from_numpy(single_mask)\n",
    "\n",
    "    # Specify output tensor\n",
    "    output_tensor = httpclient.InferRequestedOutput(\"output\")\n",
    "\n",
    "    # Perform inference\n",
    "    response = client.infer(\n",
    "        model_name=\"satvision_toa_model\",\n",
    "        inputs=[image_tensor, mask_tensor],\n",
    "        outputs=[output_tensor]\n",
    "    )\n",
    "\n",
    "    # Retrieve and print output\n",
    "    input_images.append(torch.from_numpy(np.squeeze(single_image)))\n",
    "    input_masks.append(torch.from_numpy(np.squeeze(single_mask)))\n",
    "    output_images.append(torch.from_numpy(np.squeeze(response.as_numpy(\"output\"))))\n",
    "\n",
    "# output reconstructions\n",
    "print(f\"Reconstructed {len(output_images)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad02d2be-fbe4-4616-8df7-d1a8156d5abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee96d43-d99b-4cf6-ab61-92d573a166fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_index = [0, 2, 1]\n",
    "plot_export_pdf('reconstructions.pdf', input_images, output_images, input_masks, rgb_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90fad5e-7530-4a53-b936-fa192c1a2cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
